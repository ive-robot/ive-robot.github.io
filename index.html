<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="IVE: Imagine, Verify, Execute: Agentic Exploration with Vision-Language Models">
    <meta name="keywords" content="IVE, Vision-Language Models, Agentic Exploration">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Imagine, Verify, Execute: Memory-guided Agentic Exploration with Vision-Language Models</title>

    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.ico">
    <link rel="stylesheet" href="static/css/prompts.css">

    <script src="static/js/prompts.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>



    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title"><b>Imagine, Verify, Execute</b>: Memory-guided Agentic Exploration with Vision-Language Models</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://sjlee.cc/">Seungjae Lee<sup>*</sup></a></span>
                            <span class="author-block">
                                <a href="https://danielekpo.com/">Daniel Ekpo<sup>*</sup></a></span>
                            <span class="author-block">
                                <a href="https://hdacnw.github.io/">Haowen Liu</a></span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://furong-huang.com/">Furong Huang<sup>†</sup></a></span>
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava<sup>†</sup></a></span>
                            <span class="author-block">
                                <a href="https://jbhuang0604.github.io/">Jia-Bin Huang<sup>†</sup></a></span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">University of Maryland, College Park</span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>*</sup> Equal contribution. <sup>†</sup>
                                Equal advising.</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="static/full_paper.pdf" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2505.07815" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code (Coming Soon)</span>
                                    </a>
                                </span>
                            </div>

                        </div>

                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Project video -->
    <section class="section">
        <div class="container">
            <!-- <video poster="" autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/ive_video_submission_final.mp4" type="video/mp4">
            </video> -->
            <div class="publication-video">
                <iframe src="static/videos/ive_video_submission_final.mp4" frameborder="0" allow="encrypted-media"
                    allowfullscreen allow="autoplay"></iframe>
            </div>
        </div>
    </section>
    <!-- Project video -->


    <!-- Videos -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <!-- Tangram videos -->
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/tangram_explr1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/tangram_explr2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/tangram_explr3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/tangram_explr4.mp4" type="video/mp4">
                        </video>
                    </div>

                </div>
            </div>
            <!-- Tangram videos end -->

            <!-- Object videos -->
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/object_ive_explr1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/object_ive_explr2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/object_ive_explr3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/object_ive_explr4.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
            <!-- Object videos end -->

            <!-- Simulation videos -->
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/vimabench1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/vimabench3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/vimabench3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/vimabench1.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="container">
                    <div class="columns">
                        <div id="top-video-description" class="column has-text-justified">
                            <p>The IVE (Imagine-Verify-Execute) agent autonomously explores Tangram pieces in the real
                                world (top row), commonobjects (middle row), and objects in simulation (bottom row).
                                Across these tasks, IVE converts visual input to semantic scene graphs, imagines novel
                                configurations, verifies their physical feasibility, and executes actions to gather
                                diverse, semantically-grounded data for downstream learning.</p>
                        </div>
                    </div>
                </div>

            </div>
            <!-- Simulation videos end -->



        </div>
    </section>
    <!-- End Videos -->


    <!-- Abstract -->
    <section class="section">
        <div class="container is-max-desktop">
            <h3 class="title is-3 has-text-centered">Abstract</h3>
            <div class="content has-text-justified">
                <p>Exploration is essential for general-purpose robotic learning, especially in open-ended environments where dense rewards, explicit goals, or task-specific supervision are scarce. Vision-language models (VLMs), with their semantic reasoning over objects, spatial relations, and potential outcomes, present a compelling foundation for generating high-level exploratory behaviors. However, their outputs are often ungrounded, making it difficult to determine whether imagined transitions are physically feasible or informative. To bridge the gap between imagination and execution, we present IVE (Imagine, Verify, Execute), an agentic exploration framework inspired by human curiosity. Human exploration is often driven by the desire to discover novel scene configurations and to deepen understanding of the environment. Similarly, IVE leverages VLMs to abstract RGB-D observations into semantic scene graphs, imagine novel scenes, predict their physical plausibility, and generate executable skill sequences through action tools. We evaluate IVE in both simulated and real-world tabletop environments. The results show that IVE enables more diverse and meaningful exploration than RL baselines, as evidenced by a 4.1 to 7.8× increase in the entropy of visited states. Moreover, the collected experience supports downstream learning, producing policies that closely match or exceed the performance of those trained on human-collected demonstrations.</p>
            </div>
        </div>
    </section>
    <!-- Abstract -->




    <section class="section">
        <div class="container">
            <h3 class="title is-3 has-text-centered">Method Overview</h3>
            <div>
                <figure class="image is-fullwidth has-text-justified">
                    <img src="./static/images/overview.png">
                    <figcaption class="has-text-justified">
                        <p>Overview of IVE (Imagine, Verify, Execute). The Scene Describer constructs a scene graph from
                            observations, the Explorer imagines novel configurations guided by memory
                            retrieval, and the Verifier predict the physical plausibility of proposed
                            transitions. Verified plans are executed using action tools. Exploration is
                            structured around semantic reasoning, verification, and physically grounded
                            interaction.</p>
                    </figcaption>
                </figure>
            </div>
        </div>
    </section>





    <!-- Ablation baselines -->
    <section class="section">
        <div class="container is-max-desktop">
            <h3 class="title is-3 has-text-centered">IVE vs. Human Exploration</h3>
            <figure>
                <div class="publication-video">
                    <iframe src="static/videos/data_collection_comparison.mp4" frameborder="0" allow="encrypted-media"
                        allowfullscreen></iframe>
                </div>
                <figcaption class="has-text-justified">
                    <p>IVE makes it easy to collect diverse and informative exploration data at scale. Here we show a
                        human expert collecting data using OpenTeach, a popular tool for collecting expert
                        demonstrations (left), a human-in-the-loop collecting data using the same action tools exposed
                        to IVE (middle), and IVE collecting data autonomously through embodied exploration (right).</p>
                </figcaption>
            </figure>
            <br>
            <h3 class="title is-3 has-text-centered">Results and Ablation</h3>

            <div class="results">
                <figure class="image is-fullwidth has-text-justified">
                    <img src="static/images/experiment_result_arxiv.png" alt="Experiment results">
                    <figcaption class="has-text-justified">
                        <p><strong>Exploration capability evaluation across simulated and real-world environments.</strong> Top: Growth curves of the number of unique scene graphs visited. Bottom: Diversity of visited states, measured by entropy.
                            </p>
            </div>
            <br>
            <div class="results">
                <figure class="image is-fullwidth has-text-justified">
                    <img src="static/images/ablations_baselines_main.png" alt="Ablations">
                    <figcaption class="has-text-justified">
                        <p><strong>Ablation study of IVE.</strong> (Top) Illustration of each variant, highlighting removed modules in gray. (Bottom)
                            Exploration performance is measured by the number of unique scene graphs, entropy, empowerment, and information
                            gain (see Appendix A for metric details). Removing retrieval memory causes the largest performance drop, emphasizing
                            the importance of experience-grounded generation. Verifier removal slightly degrades performance, particularly in
                            terms of information gain, but empowerment remains relatively stable. The random tool selector baseline performs the
                            worst across all metrics. Our full model (IVE) approaches human-level exploration efficiency.</p>
                    </figcaption>
                </figure>
            </div>
            <br>
            <div class="results">
                <figure class="image is-fullwidth has-text-justified">
                    <img src="static/images/ablations_baselines.png" alt="Ablation baselines">
                    <figcaption class="has-text-justified">
                        <p><strong>Exploring with Embodied Agents.</strong> IVE, powered by different Vision-Language Models (VLMs) against a human expert. The
                            plots show performance across four key metrics as a function of interaction: (Left) the
                            growth in the number of unique scene graphs discovered, (Middle Left) the entropy of visited
                            states (a measure of diversity), (Middle Right) empowerment (the agent's ability to
                            influence future states), and (Right) information gain (the amount of new information
                            acquired). Notably, IVE, regardless of the VLM used, surpasses the human expert in
                            generating unique scene graphs, achieving higher state diversity, and gaining more
                            information.</p>
                    </figcaption>
            </div>


            <!-- Goal-conditional Behavior Cloning Table -->
            <br>
            <div class="results" style="margin-top:2em;">
                <div class="table-title">Table 1: Success rates (%) of goal-conditional behavior cloning across tasks in simulation. Our method achieves human-level performance and significantly outperforms exploration RL baselines (RND (<a href="https://arxiv.org/abs/1810.12894" target="_blank"><span class="reference">Burda et al., 2019</span></a>) and RE3 (<a href="https://proceedings.mlr.press/v139/seo21a.html" target="_blank"><span class="reference">Seo et al., 2021</span></a>)), demonstrating the effectiveness of our exploration strategy in generating diverse and semantically meaningful data.</div>
                <div class="table-container">
                    <table>
                        <tr class="top-border">
                            <th rowspan="2"></th>
                            <th rowspan="2">Exploration Method</th>
                            <th colspan="2" class="multicolumn header-border">Non-conditional</th>
                            <th class="multicolumn header-border">Goal-conditional</th>
                        </tr>
                        <tr class="header-border">
                            <th># of achieved tasks</th>
                            <th>Entropy</th>
                            <th>Success rate</th>
                        </tr>
                        <tr>
                            <td rowspan="4">VIMA Bench (5 objects)</td>
                            <td>SAC (<a href="https://arxiv.org/abs/1801.01290" target="_blank"><span class="reference">Haarnoja et al., 2018</span></a>) + RND (<a href="https://arxiv.org/abs/1810.12894" target="_blank"><span class="reference">Burda et al., 2019</span></a>)</td>
                            <td class="centered">2.0</td>
                            <td class="centered">1.907</td>
                            <td class="centered">8.33%</td>
                        </tr>
                        <tr>
                            <td>SAC (<a href="https://arxiv.org/abs/1801.01290" target="_blank"><span class="reference">Haarnoja et al., 2018</span></a>)+ RE3 (<a href="https://proceedings.mlr.press/v139/seo21a.html" target="_blank"><span class="reference">Seo et al., 2021</span></a>)</td>
                            <td class="centered">2.1</td>
                            <td class="centered">1.754</td>
                            <td class="centered">0.00%</td>
                        </tr>
                        <tr>
                            <td>IVE (Ours)</td>
                            <td class="centered"><b>4.1</b></td>
                            <td class="centered"><b>2.283</b></td>
                            <td class="centered"><b>58.33%</b></td>
                        </tr>
                        <tr class="section-border">
                            <td>Human</td>
                            <td class="centered"><u>3.6</u></td>
                            <td class="centered"><u>2.021</u></td>
                            <td class="centered"><u>50.00%</u></td>
                        </tr>
                        <tr>
                            <td rowspan="4">VIMA Bench (4 objects)</td>
                            <td>SAC (<a href="https://arxiv.org/abs/1801.01290" target="_blank"><span class="reference">Haarnoja et al., 2018</span></a>) + RND (<a href="https://arxiv.org/abs/1810.12894" target="_blank"><span class="reference">Burda et al., 2019</span></a>)</td>
                            <td class="centered">2.0</td>
                            <td class="centered">1.907</td>
                            <td class="centered">0.00%</td>
                        </tr>
                        <tr>
                            <td>SAC (<a href="https://arxiv.org/abs/1801.01290" target="_blank"><span class="reference">Haarnoja et al., 2018</span></a>) + RE3 (<a href="https://proceedings.mlr.press/v139/seo21a.html" target="_blank"><span class="reference">Seo et al., 2021</span></a>)</td>
                            <td class="centered">1.2</td>
                            <td class="centered"><u>1.959</u></td>
                            <td class="centered">0.00%</td>
                        </tr>
                        <tr>
                            <td>IVE (Ours)</td>
                            <td class="centered"><u>3.1</u></td>
                            <td class="centered">1.528</td>
                            <td class="centered"><b>41.67%</b></td>
                        </tr>
                        <tr class="bottom-border">
                            <td>Human</td>
                            <td class="centered"><b>4.2</b></td>
                            <td class="centered"><b>1.897</b></td>
                            <td class="centered">33.33%</td>
                        </tr>
                    </table>
                </div>
            </div>

            <!-- World Model Evaluation Table -->
            <br>
            <div class="results" style="margin-top:2.5em;">
                <div class="table-title">Table 2: Quantitative evaluation of World Model (WM) predictions using datasets collected by different exploration methods, trained with DINO-WM (<a href="https://arxiv.org/abs/2411.04983" target="_blank"><span class="reference">Zhou et al., 2024a</span></a>).</div>
                <div class="table-container">
                    <table>
                        <tr class="top-border">
                            <th rowspan="2">Exploration Method</th>
                            <th colspan="2" class="multicolumn header-border">Sim Env 1</th>
                            <th colspan="2" class="multicolumn header-border">Sim Env 2</th>
                            <th colspan="2" class="multicolumn header-border">Real World</th>
                        </tr>
                        <tr class="header-border">
                            <th>SSIM (↑)</th>
                            <th>LPIPS (↓)</th>
                            <th>SSIM (↑)</th>
                            <th>LPIPS (↓)</th>
                            <th>SSIM (↑)</th>
                            <th>LPIPS (↓)</th>
                        </tr>
                        <tr>
                            <td>SAC (<a href="https://arxiv.org/abs/1801.01290" target="_blank"><span class="reference">Haarnoja et al., 2018</span></a>) + RND (<a href="https://arxiv.org/abs/1810.12894" target="_blank"><span class="reference">Burda et al., 2019</span></a>)</td>
                            <td class="centered"><u>0.812 ± 0.039</u></td>
                            <td class="centered">0.198 ± 0.060</td>
                            <td class="centered">0.855 ± 0.036</td>
                            <td class="centered">0.168 ± 0.061</td>
                            <td class="centered">-</td>
                            <td class="centered">-</td>
                        </tr>
                        <tr>
                            <td>SAC (<a href="https://arxiv.org/abs/1801.01290" target="_blank"><span class="reference">Haarnoja et al., 2018</span></a>) + RE3 (<a href="https://proceedings.mlr.press/v139/seo21a.html" target="_blank"><span class="reference">Seo et al., 2021</span></a>)</td>
                            <td class="centered">0.814 ± 0.040</td>
                            <td class="centered">0.199 ± 0.057</td>
                            <td class="centered">0.850 ± 0.034</td>
                            <td class="centered">0.168 ± 0.059</td>
                            <td class="centered">-</td>
                            <td class="centered">-</td>
                        </tr>
                        <tr>
                            <td>IVE (Ours)</td>
                            <td class="centered"><b>0.837 ± 0.032</b></td>
                            <td class="centered"><u>0.129 ± 0.044</u></td>
                            <td class="centered">0.853 ± 0.032</td>
                            <td class="centered"><u>0.160 ± 0.058</u></td>
                            <td class="centered">0.634 ± 0.075</td>
                            <td class="centered"><b>0.181 ± 0.056</b></td>
                        </tr>
                        <tr class="bottom-border">
                            <td>Human</td>
                            <td class="centered"><u>0.833 ± 0.032</u></td>
                            <td class="centered"><b>0.126 ± 0.042</b></td>
                            <td class="centered"><b>0.862 ± 0.027</b></td>
                            <td class="centered"><b>0.139 ± 0.047</b></td>
                            <td class="centered"><u>0.653 ± 0.072</u></td>
                            <td class="centered">0.194 ± 0.056</td>
                        </tr>
                    </table>
                </div>
            </div>
        </div>
    </section>
    <!-- Ablation baselines: -->


    <section class="section">
        <div class="container is-max-desktop">
            <div class="prompt-prompts-container">
                <!-- Prompt 1: Scene Describer -->
                <h3 class="title is-3 has-text-centered">Prompts</h3>
                <div class="prompt-prompt-card" id="scene-describer">
                    <div class="prompt-prompt-header" onclick="togglePrompt('scene-describer')">
                        <div class="prompt-prompt-title-wrapper">
                            <div class="prompt-prompt-icon prompt-icon-code">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                                    stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                    stroke-linejoin="round">
                                    <polyline points="16 18 22 12 16 6"></polyline>
                                    <polyline points="8 6 2 12 8 18"></polyline>
                                </svg>
                            </div>
                            <span class="prompt-prompt-title">Scene Describer</span>
                        </div>
                        <svg class="prompt-chevron" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                            stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <polyline points="6 9 12 15 18 9"></polyline>
                        </svg>
                    </div>
                    <div class="prompt-prompt-content">
                        <div class="prompt-prompt-text"></div>
                        <div class="prompt-prompt-actions">
                            <button class="prompt-copy-btn" onclick="copyPromptContent('scene-describer')">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                                    stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                    stroke-linejoin="round">
                                    <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                                    <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                                </svg>
                                <span>Copy</span>
                            </button>
                        </div>
                    </div>
                </div>

                <!-- Prompt 2: Explorer -->
                <div class="prompt-prompt-card" id="explorer">
                    <div class="prompt-prompt-header" onclick="togglePrompt('explorer')">
                        <div class="prompt-prompt-title-wrapper">
                            <div class="prompt-prompt-icon prompt-icon-search">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                                    stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                    stroke-linejoin="round">
                                    <circle cx="11" cy="11" r="8"></circle>
                                    <line x1="21" y1="21" x2="16.65" y2="16.65"></line>
                                </svg>
                            </div>
                            <span class="prompt-prompt-title">Explorer</span>
                        </div>
                        <svg class="prompt-chevron" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                            stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <polyline points="6 9 12 15 18 9"></polyline>
                        </svg>
                    </div>
                    <div class="prompt-prompt-content">
                        <div class="prompt-prompt-text"></div>
                        <div class="prompt-prompt-actions">
                            <button class="prompt-copy-btn" onclick="copyPromptContent('explorer')">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                                    stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                    stroke-linejoin="round">
                                    <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                                    <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                                </svg>
                                <span>Copy</span>
                            </button>
                        </div>
                    </div>
                </div>

                <!-- Prompt 3: Verifier -->
                <div class="prompt-prompt-card" id="verifier">
                    <div class="prompt-prompt-header" onclick="togglePrompt('verifier')">
                        <div class="prompt-prompt-title-wrapper">
                            <div class="prompt-prompt-icon prompt-icon-check-square">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                                    stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                    stroke-linejoin="round">
                                    <polyline points="9 11 12 14 22 4"></polyline>
                                    <path d="M21 12v7a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h11"></path>
                                </svg>
                            </div>
                            <span class="prompt-prompt-title">Verifier</span>
                        </div>
                        <svg class="prompt-chevron" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                            stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <polyline points="6 9 12 15 18 9"></polyline>
                        </svg>
                    </div>
                    <div class="prompt-prompt-content">
                        <div class="prompt-prompt-text"></div>
                        <div class="prompt-prompt-actions">
                            <button class="prompt-copy-btn" onclick="copyPromptContent('verifier')">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                                    stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                    stroke-linejoin="round">
                                    <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                                    <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                                </svg>
                                <span>Copy</span>
                            </button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- BibTeX -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h3 class="title">BibTeX</h3>
            <pre><code>@misc{lee2025imagineverifyexecutememoryguided,
    title={Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models},
    author={Seungjae Lee and Daniel Ekpo and Haowen Liu and Furong Huang and Abhinav Shrivastava and Jia-Bin Huang},
    year={2025},
    eprint={2505.07815},
    archivePrefix={arXiv}
}
</code></pre>
        </div>
    </section>
    <!-- BibTeX -->



    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="#">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="#" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p>
                            This means you are free to borrow the <a
                                href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
                            we just ask that you link back to this page in the footer.
                            Please remember to remove the analytics code included in the header of the website which
                            you do not want on your website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>