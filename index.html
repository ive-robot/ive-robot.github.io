<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="Imagine, Verify, Execute: Agentic Exploration with Vision-Language Models">
    <meta name="keywords" content="IVE, Vision-Language Models, Agentic Exploration">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Imagine, Verify, Execute: Agentic Exploration with Vision-Language Models</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.ico">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>



    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Imagine, Verify, Execute: Agentic Exploration with
                            Vision-Language Models</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="#">Anonymous</a></span>


                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Anonymous Institution,</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Video Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code (Coming Soon)</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

<!-- Videos -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <!-- Tangram videos -->
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/tangram_explr1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/tangram_explr2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/tangram_explr3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/tangram_explr4.mp4" type="video/mp4">
                        </video>
                    </div>

                </div>
            </div>
            <!-- Tangram videos end -->

            <!-- Object videos -->
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/object_ive_explr1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/object_ive_explr2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/object_ive_explr3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/object_ive_explr4.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
            <!-- Object videos end -->

            <!-- Simulation videos -->
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/vimabench1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/vimabench2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/vimabench3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item">
                        <video poster="" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/vimabench1.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
            <!-- Simulation videos end -->
        </div>
    </section>
<!-- End Videos -->

<!-- Abstract -->
    <section class="section">
        <div class="container is-max-desktop">
            <h2 class="title is-3 has-text-centered">Abstract</h2>
            <div class="content has-text-justified">
                <p>
                    Exploration is a fundamental challenge of general-purpose robotic learning, particularly in
                    open-ended environments where explicit human guidance or task-specific feedback is limited.
                    Vision-language models (VLMs), which can reason about object semantics, spatial relations,
                    and potential outcomes, offer a promising foundation for guiding exploratory behavior by
                    generating high-level goals or hypothetical transitions. However, their outputs lack
                    grounding, making it difficult to determine whether imagined transitions are physically
                    feasible or informative in the environment. To bridge this gap between imagination and
                    execution, we present IVE(Imagine, Verify, Execute), an agentic exploration framework
                    inspired by human curiosity. In humans, intrinsic motivation frequently emerges from the
                    drive to discover novel scene configurations and to make sense of the environment. This
                    process is often enhanced by verbalizing goals or intentions through language. To enable
                    this human-inspired approach, IVE abstracts RGB-D observations into semantic scene graphs,
                    imagines novel future scenes, predicts their physical plausibility, and executes actions via
                    action tools. We evaluate IVE in both simulated and real-world tabletop environments using a
                    suite of exploration metrics and downstream tasks. The results show that our method produces
                    more diverse and meaningful exploration than RL baselines with intrinsic curiosity.
                    Additionally, the data IVE collects enables downstream learning performance that closely
                    matches that of policies trained on human-collected demonstrations.
                </p>
            </div>
        </div>
    </section>
    <!-- Abstract -->



    <!-- Project video -->
    <section class="section">
        <div class="container is-max-desktop">
            <h2 class="title is-3 has-text-centered">Video</h2>
            <div class="publication-video">
                <iframe src="static/videos/paper_video_draft2.mp4" frameborder="0"
                    allow="encrypted-media" allowfullscreen></iframe>
            </div>
        </div>
    </section>
    <!-- Project video -->


    <section class="section">
        <div class="container is-max-desktop">
            <h2 class="title is-3 has-text-centered">Overview</h2>
                    <div>
                        <figure class="image is-fullwidth has-text-justified">
                            <img src="./static/images/overview.png">
                            <figcaption>
                                <p>Overview of IVE (Imagine, Verify, Execute). The Scene Describer constructs a scene graph from observations, the Explorer imagines novel configurations guided by memory
                                    retrieval, and the Verifier predict the physical plausibility of proposed
                                    transitions. Verified plans are executed using action tools. Exploration is
                                    structured around semantic reasoning, verification, and physically grounded
                                    interaction.</p>
                            </figcaption>
                        </figure>
                    </div>
        </div>
    </section>



    <!-- Ablation baselines -->
    <section class="section">
        <div class="container is-max-desktop">
            <h2 class="title is-3 has-text-centered">IVE vs. Human Exploration</h2>
            <div class="results">
                <figure class="image is-fullwidth has-text-justified">
                    <img src="static/images/ablations_baselines.png" alt="Ablation baselines">
                    <figcaption>
                        <p>Exploring with Embodied Agents: This figure compares the exploration capabilities of our method, IVE, powered by different Vision-Language Models (VLMs) against a human expert. The plots show performance across four key metrics as a function of interaction: (Left) the growth in the number of unique scene graphs discovered, (Middle Left) the entropy of visited states (a measure of diversity), (Middle Right) empowerment (the agent's ability to influence future states), and (Right) information gain (the amount of new information acquired). Notably, IVE, regardless of the VLM used, surpasses the human expert in generating unique scene graphs, achieving higher state diversity, and gaining more information.</p>
                    </figcaption>
            </div>
        </div>
    </section>
    <!--/ Ablation baselines -->


    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{anonymous2025ive,
  author    = {Anonymous},
  title     = {Imagine, Verify, Execute: Agentic Exploration with Vision-Language Models},
  journal   = {Under review},
  year      = {2025}
}</code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="#">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="#" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p>
                            This means you are free to borrow the <a
                                href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
                            we just ask that you link back to this page in the footer.
                            Please remember to remove the analytics code included in the header of the website which
                            you do not want on your website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>